<!doctype html>
<html lang="en">

<head>
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
    integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
  <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300&display=swap" rel="stylesheet"> 

  <title>RegNeRF</title>
  <style>
    *{
    font-family: 'Roboto', sans-serif;
    padding: 0;
    margin: 0;
    outline: none;
    }
  </style>
</head>

<body>
  <div class="container">
    <br>
    <div style="text-align: center;">  
      <h1>DiTalker</h1>
      <h3> DiTalker: A Unified DiT-based Framework for High-Quality and Speaking Styles Controllable Portrait Animation</h3>
      <!-- <div style="margin-top: 15px;">
        <span style="margin-right: 15px; font-size: 1.3em;"><a href="https://m-niemeyer.github.io/" target="_blank">Michael Niemeyer<sup>1,2,3</sup></a></span>
        <span style="margin-right: 15px; font-size: 1.3em;"><a href="https://jonbarron.info/" target="_blank">Jonathan T. Barron<sup>3</sup></a></span>
        <span style="margin-right: 15px; font-size: 1.3em;"><a href="https://bmild.github.io/" target="_blank">Ben Mildenhall<sup>3</sup></a></span>
      </div>
      <div>
        <span style="margin-right: 15px; font-size: 1.3em;"><a href="https://msajjadi.com/" target="_blank">Mehdi S. M. Sajjadi<sup>3</sup></a></span>
        <span style="margin-right: 15px; font-size: 1.3em;"><a href="http://cvlibs.net/" target="_blank">Andreas Geiger<sup>1,2</sup></a></span>
        <span style="font-size: 1.3em;"><a href="https://research.google/people/107229/" target="_blank">Noha Radwan<sup>3</sup></a></span>
      </div>
      <div style="margin-top: 15px;">
        <span style="margin-right: 20px; font-size: 1.2em;"><sup>1</sup>Max Planck Institute for Intelligent
          Systems</span>
        <span style="margin-right: 20px; font-size: 1.2em;"><sup>2</sup>University of TÃ¼bingen</span>
        <span style="font-size: 1.2em;"><sup>3</sup>Google Research</span>
      </div>
      <div>
        <span style="margin-right: 10px; font-size: 1.3em;">CVPR 2022 (oral)</span>
      </div> -->
    </div>
    <!-- <div class="text-center" style="font-size: 1.5em; margin-top: 25px;">
      <a class="btn btn-primary btn-lg" target="_blank"
        href="https://drive.google.com/file/d/1S_NnmhypZjyMfwqcHg-YbWSSYNWdqqlo/view?usp=sharing" role="button"
        style="margin-right: 10px; margin-bottom: 10px;">Paper</a>
      <a class="btn btn-primary btn-lg" target="_blank"
        href="https://youtu.be/QyyyvA4-Kwc" role="button"
        style="margin-right: 10px; margin-bottom: 10px;">Video</a>
      <a class="btn btn-primary btn-lg" target="_blank"
        href="https://drive.google.com/file/d/15ip8Fvfxp6rNRfBnbJEnFCjIJeFMH4CE/view?usp=sharing" role="button"
        style="margin-right: 10px; margin-bottom: 10px;">Supplementary</a>
      <a class="btn btn-primary btn-lg" target="_blank"
        href="https://arxiv.org/abs/2112.00724" role="button"
        style="margin-right: 10px;  margin-bottom: 10px;">Arxiv</a>
      <a class="btn btn-primary btn-lg" target="_blank"
        href="https://drive.google.com/file/d/1kYknB2Ap3I3avstmPxAa9IiW8m85AZEF/view?usp=sharing" role="button"
        style="margin-right: 10px; margin-bottom: 10px;">Poster</a>
      <a class="btn btn-primary btn-lg" target="_blank"
        href="https://github.com/google-research/google-research/tree/master/regnerf" role="button"
        style="margin-bottom: 10px;">Code</a>
    </div> -->
    <div class="text-center" style="font-size: 1.5em; margin-top: 25px;">
      <a class="btn btn-primary btn-lg" href="javascript:void(0);" role="button"
        style="margin-right: 10px; margin-bottom: 10px;">Paper</a>
      <a class="btn btn-primary btn-lg" href="javascript:void(0);" role="button"
        style="margin-right: 10px; margin-bottom: 10px;">Video</a>
      <a class="btn btn-primary btn-lg" href="javascript:void(0);" role="button"
        style="margin-right: 10px; margin-bottom: 10px;">Supplementary</a>
      <a class="btn btn-primary btn-lg" href="javascript:void(0);" role="button"
        style="margin-right: 10px; margin-bottom: 10px;">Arxiv</a>
      <a class="btn btn-primary btn-lg" href="javascript:void(0);" role="button"
        style="margin-right: 10px; margin-bottom: 10px;">Poster</a>
      <a class="btn btn-primary btn-lg" href="javascript:void(0);" role="button"
        style="margin-bottom: 10px;">Code</a>
    </div>
    <div class="row">
      <div class="col-md-12 col-sm-12 col-xs-12">
        <div class="embed-responsive embed-responsive-21by9">
          <video controls loop muted autoplay class="embed-responsive-item">
            <source src="C:\Users\fenghe\Desktop\ditalker\videos\speaking_style_emotion_high_quality.mp4" type="video/mp4">
          </video>
        </div>
        <p class="text-center" style="font-size: 1.5em;">
          <span style="font-weight: bold;">DiTalker</span> generates diverse portrait animation videos.
        </p>
      </div>
    </div>
    <div style="margin-top: 30px;">
      <h2 class="text-center">
        Abstract
      </h2>
      <p style="font-style: italic; margin-bottom: 5px;">
        Portrait animation aims to synthesize talking videos from a static reference face, conditioned on audio and style frame cues (\eg, emotion and head poses), while ensuring precise lip synchronization and faithful reproduction of speaking styles.
Existing diffusion-based portrait animation methods mainly focus on  lip synchronization or static emotion transformation, often overlooking dynamic styles such as  head movements.
Moreover, most of these methods rely on dual U-Net architecture, which preserves  identity consistency but incurs additional computational overhead.
To this end, we propose DiTalker, a unified DiT-based framework for speaking style controllable portrait animation.
We design a Style-Emotion Encoding Module that employs two separate branches: a style branch extracts style embeddings for head poses and movements, and an emotion branch extracts emotion features.
We further introduce an Audio-Style Fusion Module that decouples audio  and speaking styles via two parallel cross attention layers, using these features to guide the animation process.
To enhance the quality of results, we further introduce two optimization constraints: one to improve lip synchronization and the other to preserve fine-grained identity details.
Extensive experiments  demonstrate the superiority of DiTalker in terms of lip synchronization and speaking style controllability.
      </p>
      <p style="font-size: 1.2em; margin-top: 0px;">
        <span style="font-weight: bold;">TL;DR:</span> We propose DiTalker, a DiT-based model for portrait animation that achieves precise lip sync and dynamic style control through dedicated audio-style fusion, outperforming existing methods..
      </p>
    </div>
    <!-- <div style="margin-top:10px;">
      <h2 class="text-center">
        Video
      </h2>
      <div class="embed-responsive embed-responsive-16by9">
        <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/QyyyvA4-Kwc" allowfullscreen></iframe>
      </div>
    </div> -->


    <div style="margin-top: 50px;">
      <div class="text-center">
        <h2>
          Method Overview
        </h2>
        <img src="gfx\main-0409-1.png" width=100% class="img-fluid" alt="Responsive image">
      </div>
      <div style="margin-top: 35px;">
        <p>
          NeRF optimizes the reconstruction loss for a given set of input images (<span class="text-primary">blue
            cameras</span>).
          For sparse inputs, however, this leads to degenerate solutions.
          In this work, we propose to sample unobserved views (<span class="text-danger">red cameras</span>) and <span
            style="font-weight: bold;"> regularize the geometry and appearance of patches</span> rendered from those
          views.
          More specifically, we cast rays through the scene and render patches from unobserved viewpoints for a given
          radiance field f.
          We then regularize appearance by feeding the predicted RGB patches through a trained normalizing flow model
          phi
          and maximizing predicted log-likelihood.
          We regularize geometry by enforcing a smoothness loss on the rendered depth patches.
          Further, we avoid divergence at early stages of optimization by annealing the scene sampling space ofter the first iterations.
          Our approach leads to 3D-consistent representations <span style="font-weight: bold;">even for sparse input
            scenarios with as few as 3 input views</span> from which realistic novel views can be rendered.
        </p>
      </div>
    </div>

    <div style="margin-top:50px;">
      <h2 class="text-center">
        Video Results
      </h2>
      <h4>Qualitative comparison with baseline (lip synchronization)</h4>
      <div class="row">
        <div class="col-md-12 col-sm-12 col-xs-12 gallery">
          <div class="embed-responsive embed-responsive-21by9">
            <video controls loop muted autoplay class="embed-responsive-item">
              <source src="C:\Users\fenghe\Desktop\ditalker\videos\speaking_style_head_movements.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
      <h4>Qualitative comparison with baseline (speaking style controllability)</h4>
      <div class="row">
        <div class="col-md-12 col-sm-12 col-xs-12 gallery">
          <div class="embed-responsive embed-responsive-21by9">
            <video controls loop muted autoplay class="embed-responsive-item">
              <source src="C:\Users\fenghe\Desktop\ditalker\videos\speaking_style_head_movements.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
      <h4>Qualitative comparison with baseline (noisy audio input)</h4>
      <div class="row">
        <div class="col-md-12 col-sm-12 col-xs-12 gallery">
          <div class="embed-responsive embed-responsive-21by9">
            <video controls loop muted autoplay class="embed-responsive-item">
              <source src="C:\Users\fenghe\Desktop\ditalker\videos\speaking_style_head_movements.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
      <h4>Qualitative comparison with baseline (strong accents)</h4>
      <div class="row">
        <div class="col-md-12 col-sm-12 col-xs-12 gallery">
          <div class="embed-responsive embed-responsive-21by9">
            <video controls loop muted autoplay class="embed-responsive-item">
              <source src="C:\Users\fenghe\Desktop\ditalker\videos\speaking_style_head_movements.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
      <h4>Qualitative comparison with baseline (highly emotional speech)</h4>
      <div class="row">
        <div class="col-md-12 col-sm-12 col-xs-12 gallery">
          <div class="embed-responsive embed-responsive-21by9">
            <video controls loop muted autoplay class="embed-responsive-item">
              <source src="C:\Users\fenghe\Desktop\ditalker\videos\speaking_style_head_movements.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>

      <!-- <div style="margin-top:50px;">
        <h2 class="text-center">
          More Results
        </h2>
         <p style="margin-top: 10px;">
          For more results, check out <a href="comparisons.html" target="_blank">the baseline comparisons</a> or <a
            href="ours.html" target="_blank">more view synthesis results from our method</a>.
        </p> -->
        <!-- <p>For more results, check out:</p>
        <div class="row">
          <div class="col-md-6 col-sm-6 col-xs-6 gallery">
            <div class="text-center">
              <a href="comparisons.html" target="_blank">
                <h4>Comparison to Baselines</h4>
                <img src="gfx/comparisons/ours/n9trex_thumbnail.gif" alt="Comparison Image" class="rounded">
              </a>
            </div>
          </div>
          <div class="col-md-6 col-sm-6 col-xs-6 gallery">
            <div class="text-center">
              <a href="ours.html" target="_blank">
                <h4>More Results from our Method</h4>
                <img src="gfx/ours/n9_orchids_thumbnail.gif" alt="Ours Image" class="rounded">
              </a>
            </div>
          </div>
        </div>
      </div> --> 
      <!-- <div>
        <h2 class="text-center" style="margin-top: 30px;">
          Citation
        </h2>
        <p>
          If you want to cite our work, please use:
        </p>
        <pre>
        @InProceedings{Niemeyer2021Regnerf,
          author    = {Michael Niemeyer and Jonathan T. Barron and Ben Mildenhall and Mehdi S. M. Sajjadi and Andreas Geiger and Noha Radwan},  
          title     = {RegNeRF: Regularizing Neural Radiance Fields for View Synthesis from Sparse Inputs},
          booktitle = {Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)},
          year      = {2022},
        }
      </pre>
      </div> -->
      
      <div>
        <h2 class="text-center" style="margin-top: 30px;">
          Homepage Template
        </h2>
        <p>
          If you want to use this fully-responsive and easy-to-adapt homepage template, you can download it from <a href="https://github.com/m-niemeyer/regnerf" target="_blank">the github repository</a>.
        </p>
      </div>

      <!-- Optional JavaScript -->
      <!-- jQuery first, then Popper.js, then Bootstrap JS -->
      <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
        integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN"
        crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js"
        integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q"
        crossorigin="anonymous"></script>
      <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js"
        integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl"
        crossorigin="anonymous"></script>
</body>

</html>
